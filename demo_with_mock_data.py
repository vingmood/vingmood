#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºå¾®åšçƒ­æœå¸‚åœºå½±å“åˆ†æç³»ç»Ÿ
å±•ç¤ºå®Œæ•´çš„å¯è§†åŒ–åŠŸèƒ½
"""

import json
import os
from datetime import datetime, timedelta
from market_impact_analyzer import MarketImpactAnalyzer, PriceTracker, VisualizationEngine

def create_mock_hot_searches():
    """åˆ›å»ºæ¨¡æ‹Ÿçƒ­æœæ•°æ®"""
    return [
        {"rank": 1, "title": "äººå·¥æ™ºèƒ½ChatGPTå¼•å‘çƒ­è®®", "link": "https://s.weibo.com/weibo?q=ChatGPT", "hot_value": "1234567", "timestamp": "2024-01-15 10:00:00"},
        {"rank": 2, "title": "æ–°èƒ½æºæ±½è½¦é”€é‡åˆ›æ–°é«˜", "link": "https://s.weibo.com/weibo?q=æ–°èƒ½æºæ±½è½¦", "hot_value": "987654", "timestamp": "2024-01-15 10:00:00"},
        {"rank": 3, "title": "æˆ¿åœ°äº§æ”¿ç­–è°ƒæ•´", "link": "https://s.weibo.com/weibo?q=æˆ¿åœ°äº§æ”¿ç­–", "hot_value": "876543", "timestamp": "2024-01-15 10:00:00"},
        {"rank": 4, "title": "é“¶è¡Œé™æ¯æ”¿ç­–å‡ºå°", "link": "https://s.weibo.com/weibo?q=é“¶è¡Œé™æ¯", "hot_value": "765432", "timestamp": "2024-01-15 10:00:00"},
        {"rank": 5, "title": "åŒ»ç–—è®¾å¤‡é‡‡è´­æ–°è§„", "link": "https://s.weibo.com/weibo?q=åŒ»ç–—è®¾å¤‡", "hot_value": "654321", "timestamp": "2024-01-15 10:00:00"}
    ]

def create_mock_stock_data():
    """åˆ›å»ºæ¨¡æ‹Ÿè‚¡ä»·æ•°æ®"""
    import pandas as pd
    import numpy as np
    
    # æ¨¡æ‹Ÿè…¾è®¯è‚¡ä»·æ•°æ®
    dates = pd.date_range(start='2023-12-15', end='2024-02-15', freq='D')
    np.random.seed(42)
    
    # æ¨¡æ‹Ÿä»·æ ¼æ•°æ®ï¼ˆçƒ­æœå‰30å¤©ï¼Œçƒ­æœå30å¤©ï¼‰
    base_price = 320.0
    prices = []
    
    for i, date in enumerate(dates):
        if i < 30:  # çƒ­æœå‰
            price = base_price + np.random.normal(0, 5)
        elif i == 30:  # çƒ­æœå½“å¤©
            price = base_price + 15  # çƒ­æœå¯¼è‡´ä»·æ ¼ä¸Šæ¶¨
        else:  # çƒ­æœå
            price = base_price + 20 + np.random.normal(0, 8)
        
        prices.append(max(price, 100))  # ç¡®ä¿ä»·æ ¼ä¸ä¼šå¤ªä½
    
    data = pd.DataFrame({
        'Close': prices,
        'Open': [p + np.random.normal(0, 2) for p in prices],
        'High': [p + abs(np.random.normal(0, 3)) for p in prices],
        'Low': [p - abs(np.random.normal(0, 3)) for p in prices],
        'Volume': [np.random.randint(1000000, 5000000) for _ in prices]
    }, index=dates)
    
    data['stock_name'] = 'è…¾è®¯'
    data['symbol'] = '00700.HK'
    
    return data

def demo_complete_analysis():
    """æ¼”ç¤ºå®Œæ•´åˆ†ææµç¨‹"""
    print("ğŸš€ å¾®åšçƒ­æœå¸‚åœºå½±å“åˆ†æç³»ç»Ÿ - æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤º")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç»„ä»¶
    analyzer = MarketImpactAnalyzer()
    tracker = PriceTracker()
    visualizer = VisualizationEngine()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "demo_output"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # è·å–æ¨¡æ‹Ÿçƒ­æœæ•°æ®
    hot_searches = create_mock_hot_searches()
    print(f"ğŸ“Š è·å–åˆ° {len(hot_searches)} æ¡æ¨¡æ‹Ÿçƒ­æœæ•°æ®")
    
    # åˆ†ææ¯ä¸ªçƒ­æœè¯é¢˜
    market_analyses = []
    price_analyses = []
    
    for i, hot_search in enumerate(hot_searches):
        topic = hot_search['title']
        timestamp = hot_search['timestamp']
        
        print(f"\nğŸ” åˆ†æè¯é¢˜ {i+1}: {topic}")
        
        # åˆ†æå¸‚åœºå½±å“
        market_analysis = analyzer.analyze_topic_impact(topic, timestamp)
        market_analyses.append(market_analysis)
        
        print(f"   ğŸ“ˆ ç›¸å…³å¸‚åœº: {market_analysis['market']}")
        print(f"   ğŸ¯ ç½®ä¿¡åº¦: {market_analysis['confidence']:.2f}")
        print(f"   ğŸ’¡ æ˜¯å¦æœ‰å½±å“: {'æ˜¯' if market_analysis['has_impact'] else 'å¦'}")
        
        # å¦‚æœæœ‰å¸‚åœºå½±å“ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œè‚¡ä»·åˆ†æ
        if market_analysis['has_impact'] or market_analysis['market'] in ['ç§‘æŠ€', 'æ±½è½¦']:
            print(f"   ğŸ“Š å¼€å§‹è‚¡ä»·åˆ†æ...")
            
            # åˆ›å»ºæ¨¡æ‹Ÿè‚¡ä»·åˆ†æç»“æœ
            mock_stock_data = create_mock_stock_data()
            
            # æ¨¡æ‹Ÿè‚¡ä»·åˆ†æ
            topic_date = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')
            before_data = mock_stock_data[mock_stock_data.index <= topic_date]
            after_data = mock_stock_data[mock_stock_data.index > topic_date]
            
            if not before_data.empty and not after_data.empty:
                before_avg_price = before_data['Close'].mean()
                after_avg_price = after_data['Close'].mean()
                price_change = (after_avg_price - before_avg_price) / before_avg_price * 100
                
                before_volatility = before_data['Close'].std() / before_data['Close'].mean() * 100
                after_volatility = after_data['Close'].std() / after_data['Close'].mean() * 100
                
                mock_price_analysis = {
                    'topic': topic,
                    'timestamp': timestamp,
                    'market': market_analysis['market'],
                    'analysis_period': '2023-12-15 åˆ° 2024-02-15',
                    'stock_analysis': {
                        '00700.HK': {
                            'stock_name': 'è…¾è®¯',
                            'symbol': '00700.HK',
                            'before_avg_price': round(before_avg_price, 2),
                            'after_avg_price': round(after_avg_price, 2),
                            'price_change_pct': round(price_change, 2),
                            'before_volatility': round(before_volatility, 2),
                            'after_volatility': round(after_volatility, 2),
                            'max_price_before': round(before_data['Close'].max(), 2),
                            'min_price_before': round(before_data['Close'].min(), 2),
                            'max_price_after': round(after_data['Close'].max(), 2),
                            'min_price_after': round(after_data['Close'].min(), 2),
                            'data_points_before': len(before_data),
                            'data_points_after': len(after_data)
                        }
                    }
                }
                
                price_analyses.append(mock_price_analysis)
                
                print(f"   ğŸ’° è…¾è®¯è‚¡ä»·å˜åŒ–: {price_change:+.2f}%")
                print(f"   ğŸ“ˆ æ³¢åŠ¨ç‡å˜åŒ–: {before_volatility:.2f}% â†’ {after_volatility:.2f}%")
                
                # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
                chart_filename = f"price_analysis_{market_analysis['market']}_{i+1}.html"
                chart_path = os.path.join(output_dir, chart_filename)
                visualizer.create_price_analysis_chart(mock_price_analysis, chart_path)
                print(f"   ğŸ“Š å›¾è¡¨å·²ç”Ÿæˆ: {chart_filename}")
    
    # ç”Ÿæˆæ€»ç»“å›¾è¡¨
    print(f"\nğŸ“Š ç”Ÿæˆå¸‚åœºå½±å“æ€»ç»“å›¾è¡¨...")
    summary_chart_path = os.path.join(output_dir, "market_impact_summary.html")
    visualizer.create_market_impact_summary(market_analyses, summary_chart_path)
    
    # ä¿å­˜åˆ†æç»“æœ
    print(f"\nğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")
    
    # ä¿å­˜çƒ­æœæ•°æ®
    hot_searches_path = os.path.join(output_dir, "hot_searches.json")
    with open(hot_searches_path, 'w', encoding='utf-8') as f:
        json.dump(hot_searches, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜å¸‚åœºåˆ†æç»“æœ
    market_analyses_path = os.path.join(output_dir, "market_analyses.json")
    with open(market_analyses_path, 'w', encoding='utf-8') as f:
        json.dump(market_analyses, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜è‚¡ä»·åˆ†æç»“æœ
    if price_analyses:
        price_analyses_path = os.path.join(output_dir, "price_analyses.json")
        with open(price_analyses_path, 'w', encoding='utf-8') as f:
            json.dump(price_analyses, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    total_topics = len(market_analyses)
    impactful_topics = len([a for a in market_analyses if a['has_impact']])
    market_distribution = {}
    
    for analysis in market_analyses:
        market = analysis['market']
        market_distribution[market] = market_distribution.get(market, 0) + 1
    
    summary_report = {
        'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total_topics_analyzed': total_topics,
        'impactful_topics': impactful_topics,
        'impact_rate': round(impactful_topics / total_topics * 100, 2) if total_topics > 0 else 0,
        'market_distribution': market_distribution,
        'price_analyses_count': len(price_analyses),
        'analysis_period': '30å¤©å‰ åˆ° 30å¤©å'
    }
    
    summary_path = os.path.join(output_dir, "summary_report.json")
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary_report, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
    report_path = os.path.join(output_dir, "analysis_report.txt")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("å¾®åšçƒ­æœå¸‚åœºå½±å“åˆ†ææŠ¥å‘Š (æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤º)\n")
        f.write("=" * 50 + "\n\n")
        
        f.write(f"åˆ†ææ—¶é—´: {summary_report['analysis_time']}\n")
        f.write(f"åˆ†æè¯é¢˜æ€»æ•°: {summary_report['total_topics_analyzed']}\n")
        f.write(f"æœ‰å½±å“è¯é¢˜æ•°: {summary_report['impactful_topics']}\n")
        f.write(f"å½±å“ç‡: {summary_report['impact_rate']}%\n")
        f.write(f"è‚¡ä»·åˆ†ææ•°é‡: {summary_report['price_analyses_count']}\n")
        f.write(f"åˆ†æå‘¨æœŸ: {summary_report['analysis_period']}\n\n")
        
        f.write("å¸‚åœºåˆ†å¸ƒ:\n")
        f.write("-" * 20 + "\n")
        for market, count in summary_report['market_distribution'].items():
            f.write(f"{market}: {count} ä¸ªè¯é¢˜\n")
        f.write("\n")
        
        f.write("è¯¦ç»†åˆ†æç»“æœ:\n")
        f.write("-" * 20 + "\n")
        
        for i, analysis in enumerate(market_analyses, 1):
            f.write(f"{i}. è¯é¢˜: {analysis['topic']}\n")
            f.write(f"   å¸‚åœº: {analysis['market']}\n")
            f.write(f"   ç½®ä¿¡åº¦: {analysis['confidence']:.2f}\n")
            f.write(f"   æ˜¯å¦æœ‰å½±å“: {'æ˜¯' if analysis['has_impact'] else 'å¦'}\n")
            f.write(f"   ç›¸å…³è‚¡ç¥¨: {', '.join(analysis['related_stocks']) if analysis['related_stocks'] else 'æ— '}\n")
            f.write(f"   é¾™å¤´ä¼ä¸š: {', '.join(analysis['market_leaders']) if analysis['market_leaders'] else 'æ— '}\n")
            f.write("\n")
        
        if price_analyses:
            f.write("è‚¡ä»·å½±å“åˆ†æ:\n")
            f.write("-" * 20 + "\n")
            
            for i, price_analysis in enumerate(price_analyses, 1):
                f.write(f"{i}. è¯é¢˜: {price_analysis['topic']}\n")
                f.write(f"   å¸‚åœº: {price_analysis['market']}\n")
                f.write(f"   åˆ†æå‘¨æœŸ: {price_analysis['analysis_period']}\n")
                
                for symbol, stock_data in price_analysis['stock_analysis'].items():
                    f.write(f"   {stock_data['stock_name']} ({symbol}):\n")
                    f.write(f"     ä»·æ ¼å˜åŒ–: {stock_data['price_change_pct']:.2f}%\n")
                    f.write(f"     çƒ­æœå‰å¹³å‡ä»·æ ¼: {stock_data['before_avg_price']}\n")
                    f.write(f"     çƒ­æœåå¹³å‡ä»·æ ¼: {stock_data['after_avg_price']}\n")
                    f.write(f"     æ³¢åŠ¨ç‡å˜åŒ–: {stock_data['before_volatility']:.2f}% -> {stock_data['after_volatility']:.2f}%\n")
                f.write("\n")
    
    print(f"\nâœ… æ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}")
    print(f"ğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
    
    for filename in os.listdir(output_dir):
        print(f"   â€¢ {filename}")
    
    print(f"\nğŸŒ å¯è§†åŒ–å›¾è¡¨:")
    print(f"   â€¢ market_impact_summary.html - å¸‚åœºå½±å“æ€»ç»“")
    for i in range(len(price_analyses)):
        print(f"   â€¢ price_analysis_*.html - è‚¡ä»·åˆ†æå›¾è¡¨")
    
    print(f"\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print(f"   1. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹äº¤äº’å¼å›¾è¡¨")
    print(f"   2. æŸ¥çœ‹JSONæ–‡ä»¶äº†è§£è¯¦ç»†æ•°æ®")
    print(f"   3. æŸ¥çœ‹TXTæ–‡ä»¶äº†è§£åˆ†ææŠ¥å‘Š")

if __name__ == "__main__":
    demo_complete_analysis()